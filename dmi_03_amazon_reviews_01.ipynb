{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbogde/pandamonium/blob/main/dmi_03_amazon_reviews_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "645a916a-e538-4da9-83df-4ac694ae2ce6",
      "metadata": {
        "id": "645a916a-e538-4da9-83df-4ac694ae2ce6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "time.sleep(12)\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "45292fb9-3914-4ba8-9f60-afeeb0ad9b11",
      "metadata": {
        "id": "45292fb9-3914-4ba8-9f60-afeeb0ad9b11"
      },
      "outputs": [],
      "source": [
        "## Define URLs for Scraping Amazon Reviews\n",
        "urls = [\n",
        "    'https://www.amazon.co.uk/eufy-Auto-Lift-Self-Drying-Self-Emptying-Self-Refilling/dp/B0CPDVV72T',\n",
        "    'https://www.amazon.co.uk/dp/B0CYZH3D7Y',\n",
        "    'https://www.amazon.co.uk/dp/B0D2D66R82'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e129ae12-09d9-497d-91f7-b01bd09473b2",
      "metadata": {
        "id": "e129ae12-09d9-497d-91f7-b01bd09473b2"
      },
      "outputs": [],
      "source": [
        "reviews_list = []\n",
        "ratings_list = []\n",
        "\n",
        "# Iterate over each movie URL\n",
        "for url in urls:\n",
        "    print(f\"Scraping: {url}\")\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}  # Prevent getting blocked\n",
        "    page = requests.get(url, headers=headers)\n",
        "\n",
        "    print(f\"page: {page}\\n\")\n",
        "    # print(f\"page.content,: {page.content}\\n\")\n",
        "\n",
        "    # Parse the page content\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "    # Find all review containers\n",
        "    review_containers = soup.find_all('li', class_='review aok-relative')\n",
        "    print(f\"review_containers: {review_containers}\\n\")\n",
        "\n",
        "    # Extract review text and rating\n",
        "    for container in review_containers:\n",
        "        # Extract review text\n",
        "        review_element = container.find('span', class_='a-icon-alt')\n",
        "        print(f\"review_element: {review_element}\\n\")\n",
        "\n",
        "        review_text = review_element.get_text(strip=True) if review_element else \"No Review\"\n",
        "\n",
        "        # Extract rating\n",
        "        rating_element = container.find('span', class_='ipc-rating-star--rating')\n",
        "        rating = rating_element.get_text(strip=True) if rating_element else \"NA\"\n",
        "\n",
        "        # Append to lists\n",
        "        reviews_list.append(review_text)\n",
        "        ratings_list.append(rating)\n",
        "\n",
        "        # print(f\"Review: {review_text[:100]}...\")  # Print preview\n",
        "        # print(f\"Rating: {rating}\\n\")\n",
        "\n",
        "    # Sleep to prevent being blocked\n",
        "    time.sleep(13)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e1009af5-dd01-408b-b509-c372ecb15740",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "e1009af5-dd01-408b-b509-c372ecb15740",
        "outputId": "746b0a9c-3835-4d9d-99ca-697c2699b744"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-74ccb8e4a29f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"   \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "print(reviews_list[1], \"   \", ratings_list[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30bc6d5-1456-4647-b195-c5c4bdf8309b",
      "metadata": {
        "id": "b30bc6d5-1456-4647-b195-c5c4bdf8309b"
      },
      "outputs": [],
      "source": [
        "movie = pd.DataFrame({'Review': reviews_list, 'Rating': ratings_list})\n",
        "\n",
        "# Save to CSV\n",
        "movie.to_csv('Workshop3_IMDB_Dataset.csv', index=False)\n",
        "\n",
        "# Display first few rows\n",
        "print(movie.head())\n",
        "print(movie.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b145104-05fc-48e7-8afe-b416e29d8c05",
      "metadata": {
        "id": "5b145104-05fc-48e7-8afe-b416e29d8c05"
      },
      "outputs": [],
      "source": [
        "comments=[\"This is a good film\",\"Interesting film\",\"I do not like film\", \"Such a wonderful movie\",\"very interesting film\",\n",
        "         \"This film is about love story\",\"Do not watch this film\",\"I love this film\", \"I do not know, I feel it is an interesting film\",\n",
        "         \"I like to watch film again\", \"This film is awesome\", \"I recommend watching this film to everyone, enjoy it\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f604a6-6b85-4873-a133-8f1f67980fce",
      "metadata": {
        "id": "e0f604a6-6b85-4873-a133-8f1f67980fce"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "text = ', '.join(t for t in comments)\n",
        "#print(text)\n",
        "stopwords = set(STOPWORDS)\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color='white').generate(text)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432a398b-18f8-4bbb-9106-7f2fed73e8c9",
      "metadata": {
        "id": "432a398b-18f8-4bbb-9106-7f2fed73e8c9"
      },
      "outputs": [],
      "source": [
        "### WordCloud Visualization\n",
        "\n",
        "\n",
        "\n",
        "text = ', '.join(t for t in movie['Review'])\n",
        "stopwords = set(STOPWORDS)\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color='white').generate(text)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "e0ygS77oGoXx"
      },
      "id": "e0ygS77oGoXx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a63e87c-8e1d-4da5-b2bb-d397e0f8a5a8",
      "metadata": {
        "id": "8a63e87c-8e1d-4da5-b2bb-d397e0f8a5a8"
      },
      "outputs": [],
      "source": [
        "#https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n",
        "sid_obj = SentimentIntensityAnalyzer()\n",
        "sentiment_dict = sid_obj.polarity_scores(\"It tries to engage the people who are watching it. It tries to suprise people, however, this film is not interesting\")\n",
        "#sentiment_dict = sid_obj.polarity_scores(\"I love this film. It is wonderful!\")\n",
        "#sentiment_dict = sid_obj.polarity_scores(\"I am not sure about this film, no idea!\")\n",
        "print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
        "print(\"Sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
        "print(\"Sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
        "print(\"Sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
        "\n",
        "print(\"Sentence Overall Rated As\", end=\" \")\n",
        "\n",
        "    # Decide sentiment as positive, negative, or neutral\n",
        "if sentiment_dict['compound'] >= 0.05 :\n",
        "    print(\"Positive\")\n",
        "elif sentiment_dict['compound'] <= -0.05 :\n",
        "    print(\"Negative\")\n",
        "else :\n",
        "    print(\"Neutral\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a56b638f-a932-4833-9778-4d79e1419b81",
      "metadata": {
        "id": "a56b638f-a932-4833-9778-4d79e1419b81"
      },
      "outputs": [],
      "source": [
        "#use this when you have an offline dataset\n",
        "#movie =  pd.read_csv(\"F:\\A-universities\\WLV\\workshop\\Workshop3_IMDB_Dataset.csv\")\n",
        "#print(movie.head())\n",
        "#print(movie.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410f251f-b69f-4da1-806e-1bc3d0165a6f",
      "metadata": {
        "id": "410f251f-b69f-4da1-806e-1bc3d0165a6f"
      },
      "outputs": [],
      "source": [
        "# Convert Rating to string first, then replace non-numeric values safely\n",
        "movie['Rating'] = pd.to_numeric(movie['Rating'], errors='coerce')\n",
        "#NaN represents missing or undefined data\n",
        "# Fill NaN values with a default value (e.g., 0) before converting to integer\n",
        "movie['Rating'] = movie['Rating'].fillna(0).astype(int)\n",
        "\n",
        "### Extract Reviews and Ratings\n",
        "## Text Processing and Analysis\n",
        "### Importing Required Libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9ebd92-6fa9-4972-8cc1-5a2a2ed4da40",
      "metadata": {
        "id": "ac9ebd92-6fa9-4972-8cc1-5a2a2ed4da40"
      },
      "outputs": [],
      "source": [
        "# content = []\n",
        "# for url in urls:\n",
        "#     page = requests.get(url, timeout=2.50)\n",
        "#     soup = BeautifulSoup(page.content, 'html.parser')\n",
        "#     content.append(soup.find_all('div', class_='review-container'))\n",
        "\n",
        "# Initialize lists to store extracted reviews and ratings\n",
        "# Create DataFrame\n",
        "\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "##Sentiment Identification using VADER\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "sentiments = []\n",
        "\n",
        "for review in movie['Review']:\n",
        "    score = sid.polarity_scores(review)['compound']\n",
        "    if score >= 0.05:\n",
        "        sentiments.append('positive')\n",
        "    elif score <= -0.05:\n",
        "        sentiments.append('negative')\n",
        "    else:\n",
        "        sentiments.append('neutral')\n",
        "\n",
        "movie['Sentiment'] = sentiments\n",
        "\n",
        "## Sentiment Classification using Machine Learning\n",
        "\n",
        "movie['class-label'] = movie['Rating'].astype(int).apply(lambda x: '1' if x > 5 else ('-1' if x < 5 else '0'))\n",
        "movie = movie[movie['class-label'] != '0']\n",
        "\n",
        "#movie.to_csv('f:\\myfile1.csv', index=False)\n",
        "#analyzer is used to set the level of processing, it can be a character or a word level, 'word' or 'char'\n",
        "#stop_words can provide you with a list of words that have to be removed from the data before calculations;\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
        "#Once you've created a vectorizer instance, it's time to obtain a TF-IDF matrix.\n",
        "#You can use the fit_transform() class method and shape to print out its dimension:\n",
        "X = tfidf_vectorizer.fit_transform(movie['Review'])\n",
        "#print(f\"Matrix dimension: {tfidf_matrix.shape}\")\n",
        "print(f\"Matrix dimension: {X.shape}\")\n",
        "y = movie['class-label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n",
        "\n",
        "## Train and Evaluate SVM Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a375dfae-3d4c-496f-b951-952d7b921bcd",
      "metadata": {
        "id": "a375dfae-3d4c-496f-b951-952d7b921bcd"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Not Approved\", \"Approved\"])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "#print('Confusion Matrix:', confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#How to interprete these metrics?\n",
        "#https://www.statology.org/sklearn-classification-report/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a8c04c0-dcfb-499f-81d3-d10b439c4b45",
      "metadata": {
        "id": "2a8c04c0-dcfb-499f-81d3-d10b439c4b45"
      },
      "outputs": [],
      "source": [
        "## Train and Evaluate Decision Tree Classifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "y_pred = dtree.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Not Approved\", \"Approved\"])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "#print('Confusion Matrix:', confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d76b72-facc-4bd0-ad51-2929dae3b684",
      "metadata": {
        "id": "f9d76b72-facc-4bd0-ad51-2929dae3b684"
      },
      "outputs": [],
      "source": [
        "#https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format\n",
        "#use this when you have an offline dataset\n",
        "# movie1 =  pd.read_csv(\"F:\\A-universities\\WLV\\workshop\\Week 3\\IMDB\\Valid.csv\")\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive, data_table\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    file_path = '/content/drive/My Drive/Colab Notebooks/data-mining/data/Valid.csv'\n",
        "    data_table.enable_dataframe_formatter()\n",
        "else:\n",
        "    file_path = './data/Valid.csv'  # Local path\n",
        "\n",
        "movie1 = pd.read_csv(file_path)\n",
        "\n",
        "print(movie1.head())\n",
        "print(movie.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9c0637-2d68-4a90-8ed9-d546aeb53054",
      "metadata": {
        "id": "4c9c0637-2d68-4a90-8ed9-d546aeb53054"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "text = ', '.join(t for t in movie1['text'])\n",
        "stopwords = set(STOPWORDS)\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color='white').generate(text)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a04451e-3bb2-40f3-94d1-a6c4e08ea694",
      "metadata": {
        "id": "9a04451e-3bb2-40f3-94d1-a6c4e08ea694"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "##Sentiment Identification using VADER\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "sentiments = []\n",
        "\n",
        "for review in movie1['text']:\n",
        "    score = sid.polarity_scores(review)['compound']\n",
        "    if score >= 0.05:\n",
        "        sentiments.append('positive')\n",
        "    elif score <= -0.05:\n",
        "        sentiments.append('negative')\n",
        "    else:\n",
        "        sentiments.append('neutral')\n",
        "\n",
        "movie1['Sentiment'] = sentiments\n",
        "\n",
        "## Sentiment Classification using Machine Learning\n",
        "\n",
        "\n",
        "# movie1.to_csv('f:\\myfile1.csv', index=False)\n",
        "#analyzer is used to set the level of processing, it can be a character or a word level, 'word' or 'char'\n",
        "#stop_words can provide you with a list of words that have to be removed from the data before calculations;\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
        "#Once you've created a vectorizer instance, it's time to obtain a TF-IDF matrix.\n",
        "#You can use the fit_transform() class method and shape to print out its dimension:\n",
        "X = tfidf_vectorizer.fit_transform(movie1['text'])\n",
        "#print(f\"Matrix dimension: {tfidf_matrix.shape}\")\n",
        "print(f\"Matrix dimension: {X.shape}\")\n",
        "y = movie1['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n",
        "\n",
        "## Train and Evaluate SVM Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81629eab-f25d-48ac-bd7e-eb2a7bd7c7cb",
      "metadata": {
        "id": "81629eab-f25d-48ac-bd7e-eb2a7bd7c7cb"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "#conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "#disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Not Approved\", \"Approved\"])\n",
        "#disp.plot(cmap='Blues', values_format='d')\n",
        "#plt.title(\"Confusion Matrix\")\n",
        "#plt.show()\n",
        "\n",
        "#print('Confusion Matrix:', confusion_matrix(y_test, y_pred))\n",
        "#print(classification_report(y_test, y_pred))\n",
        "\n",
        "#How to interprete these metrics?\n",
        "#https://www.statology.org/sklearn-classification-report/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ade0a36-cb2a-4498-a629-1c7638bd1aaa",
      "metadata": {
        "id": "0ade0a36-cb2a-4498-a629-1c7638bd1aaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "movie1['class-label'] = movie1['Sentiment'].apply(lambda x: 1 if x == \"positive\" else  0)\n",
        "count=0\n",
        "for i in range(0,len(set_2)-1):\n",
        "    if set_1[i]==set_2[i]:\n",
        "        count=count+1\n",
        "print(count/len(set_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00480d26-04f2-41a8-87d9-4030e61480cf",
      "metadata": {
        "id": "00480d26-04f2-41a8-87d9-4030e61480cf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851ade62-43af-4b1e-81f7-a75f3d4f62b3",
      "metadata": {
        "id": "851ade62-43af-4b1e-81f7-a75f3d4f62b3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}